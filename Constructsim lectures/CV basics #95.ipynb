{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logos/TClogo.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRESENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS Developers Live Class n95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/LC95.jpg\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REQUIREMENTS** :\n",
    "- **Basics of Linux**. If you don't have that knowledge, [check our FREE online course](https://www.robotigniteacademy.com/en/course/linux-robotics/details/)\n",
    "<img src=\"images/logos/Linux.png\" width=\"200\">\n",
    "\n",
    "- **Python Basics**. If you don't have that knowledge, [check our FREE online course](https://www.robotigniteacademy.com/en/course/python-basics/details/)\n",
    "<img src=\"images/logos/python.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use this ROSject\n",
    "\n",
    "A <a href=\"http://rosjects.com\">**ROSject**</a> is a **ROS project** packaged in such a way that all the material it contains (**ROS code, Gazebo simulations and Notebooks**) can be shared with any body **using only a web link**. That is what we did with all the attendants to the Live Class, we shared this ROSject with them (so they can have access to all the ROS material they contain).\n",
    "\n",
    "**Check <a heref=\"https://youtu.be/g2Zg31pc-XM\">this Live Class video</a> to learn more about ROSjects and how to create your own ROSjects**.\n",
    "\n",
    "You will need to have a free account at the <a href=\"http://rosds.online\">ROS Development Studio</a> (ROSDS). Get the account and then follow the indications below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## ROS Developers Day-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--<img src=\"images/3-ROSDD-web-cover.jpg\" />-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Register at: http://www.rosdevday.com/-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--5% off coupon for **ROSDevDay** Registration: **M86352LC94**\n",
    "\n",
    "Valid until: Jun 14, 2020 Midnight -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's setup the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to launch the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the Simulations menu at the top of the window and click on the **Choose launch file...** button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/useful_images/simulations_menu.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, from the list of available launch files, select the launch file named **course_simulation.launch**, form the **course_simulation** package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have something similar to the next image in the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lc95-sim.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Basics for Robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This ROSject has been created by Christian Chavez and Alberto Ezquerro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer vision in a nutshell \n",
    "\n",
    "Computer vision, commonly abbreviated as CV, could be described as a field of study that allows a computer to analyze and have understanding of an uploaded digital image or group of images, such as videos.\n",
    "\n",
    "The main idea of ​​CV, along with robotics and other fields of study, is to improve tasks that could be exhaustive or repetitive for humans. In recent years, there have been many improvements with the invention of complex computer vision and deep learning systems, such as the well-known convolutional neural networks. These inventions shifted the point of view to solve many problems, such as facial recognition or medical images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "First of all, we need to understand what exactly an image is. Colloquially, we could describe it as a visual representation of something that by itself is a set of many characteristics as color, shapes, etc. For a computer, an image could be better described as a matrix, in which every value is considered a pixel, so when you are talking about a 1080p image resolution, you are referring to an specific 1080x1920 px matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Resources/Color_Channels.png\" width = 35% /></div>\n",
    "\n",
    "In the case of a colored image, we are talking about a three-dimensional matrix where each dimension corresponds to an specific color channel (Red, green, blue). The dimensions of this matrix will be different for different color spaces, which we will discuss further in the OpenCV course.\n",
    "\n",
    "We can describe an image in many more complex ways, like the color construction that is a result mainly of the light over the object surface. When we have something black, it is actually the lack of light. The color formation will depend on the wavelength of the main components of white light.\n",
    "\n",
    "If you like physics as much as I do, you will find interesting a phenomenon where the color deformation can be seen: the stars. In many pictures of space, you can see that the rock formations that are far from us have a red color, while the closest ones have a blue color. This phenomenon was discovered by the North American astronomer Edwin Hubble in 1929. We know that the space is in constant expansion, so if the space is deformed, the light that we receive from those stars will suffer from that expansion too. As a consequence the wavelength of the light will be higher and the color we perceive will have a red tone instead of a blue one. \n",
    "\n",
    "This image is a open source of the NASA. You can find it at https://images.nasa.gov/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Resources/nasa_Spiral.jpg\" width = 35% /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CvBridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, you have to know that ROS pass images from its sensors using  its own [sensor_msgs/Image](http://docs.ros.org/api/sensor_msgs/html/msg/Image.html) message format, but sometimes you need to use this images with **OpenCV** in order to work properly wiht Computer vision algortihms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately we have **CvBridge**, and is a ROS library that provides an interface between ROS and OpenCV, converting ROS images to an Open CV format and vice versa like this image. This image is take it from [this wiki]( http://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Resources/cvbridge3.png\" width = 50% /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want more information about this you can visit [this wiki of ros](http://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how you will use it, well you will see similar code like the following one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "1 from from cv_bridge import CvBridge\n",
    "2 bridge = CvBridge()\n",
    "3 cv_image = bridge.imgmsg_to_cv2(image_message, desired_encoding='passthrough')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at this example and try to find these **three** parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import cv2\n",
    "\n",
    "\n",
    "class ShowingImage(object):\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.image_sub = rospy.Subscriber(\"/camera/rgb/image_raw\",Image,self.camera_callback)\n",
    "        self.bridge_object = CvBridge()\n",
    "\n",
    "    def camera_callback(self,data):\n",
    "        try:\n",
    "            # We select bgr8 because its the OpenCV encoding by default\n",
    "            cv_image = self.bridge_object.imgmsg_to_cv2(data, desired_encoding=\"bgr8\")\n",
    "        except CvBridgeError as e:\n",
    "            print(e)\n",
    "        \n",
    "        cv2.imshow('image',cv_image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    showing_image_object = ShowingImage()\n",
    "    rospy.init_node('line_following_node', anonymous=True)\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know **cv_bridge**, let's try to work with some Open CV code, let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and writing an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opencv has some algorithms that permit work easily with images, the principal some of them are **cv2.imread** , **cv2.imwrite** and **cv2.imshow**. For example, here is a simple code in python that use some of these algorithms, let's see ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "#Import the Opencv Library\n",
    "import cv2\n",
    "\n",
    "#Read the image file\n",
    "img = cv2.imread('test_image_1.jpg')\n",
    "\n",
    "#Display the image in a window\n",
    "cv2.imshow('image',img)\n",
    "\n",
    "#The window will close after a key press\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, if we want to use it with ROS how do they work?. let's have a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside your *catkin_ws*, create a new package named **live_class**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd catkin_ws/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catkin_create_pkg live_class rospy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside this new package, create a new file named **load_image.py**, and paste the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load_image.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class LoadImage(object):\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.image_sub = rospy.Subscriber(\"/camera/rgb/image_raw\",Image,self.camera_callback)\n",
    "        self.bridge_object = CvBridge()\n",
    "\n",
    "    def camera_callback(self,data):\n",
    "        try:\n",
    "            # We select bgr8 because its the OpenCV encoding by default\n",
    "            cv_image = self.bridge_object.imgmsg_to_cv2(data, desired_encoding=\"bgr8\")\n",
    "        except CvBridgeError as e:\n",
    "            print(e)\n",
    "        example_path = '/home/user/notebook_ws/images/Course_images/test_image_1.jpg'    \n",
    "        img = cv2.imread(example_path)\n",
    "        os.chdir('/home/user/catkin_ws/src/live_class/src/')\n",
    "        cv2.imwrite('drone_image.jpg',cv_image)\n",
    "        cv2.imshow('image',img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    load_image_object = LoadImage()\n",
    "    rospy.init_node('load_image_node', anonymous=True)\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a launch file named **load_image.launch**, that starts the above program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load_image.launch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<launch>\n",
    "    <node pkg=\"live_class\" type=\"load_image.py\" name=\"load_image\"  output=\"screen\">\n",
    "    </node>\n",
    "</launch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see two important things, the first an espectacular pictura open source of the NASA in the **graphical tools**, and the second is that in the direction you specify in the program, you will have a new image. Yes, as you think is a picture taken from the drone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Course_images/universe.png\"  /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make a similar code but, instead of showing the galaxy image, let's visualize the picture taken from the drone, and at the same time, let's visualize the images taken from the drone's camera right now. You will see the difference between them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new file inside the **live_class** package and call it **load_image2.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load_image2.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "class LoadImage(object):\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.image_sub = rospy.Subscriber(\"/camera/rgb/image_raw\",Image,self.camera_callback)\n",
    "        self.bridge_object = CvBridge()\n",
    "\n",
    "    def camera_callback(self,data):\n",
    "        try:\n",
    "            # We select bgr8 because its the OpenCV encoding by default\n",
    "            cv_image = self.bridge_object.imgmsg_to_cv2(data, desired_encoding=\"bgr8\")\n",
    "        except CvBridgeError as e:\n",
    "            print(e)\n",
    "        example_path = '/home/user/catkin_ws/src/live_class/src/drone_image.jpg'    \n",
    "        img = cv2.imread(example_path)\n",
    "        cv2.imshow('image',img)\n",
    "        cv2.imshow('real_image',cv_image)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    load_image_object = LoadImage()\n",
    "    rospy.init_node('load_image_node', anonymous=True)\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the result looks like this Congratulations! You made the first step using computer vision with ROS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Course_images/exercise_1.png\"  /></div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into color filtering, you need to understand the concept of space colors. We are going to use it often during the OpenCV course. Additionally, it will help you to experiment with different color spaces for different applications. A space color is no more than a three-dimensional model that tries to describe the human perception known as color, where the coordinates of the model will define an specific color. One of them that you may know is the RGB, where all the colors are created by mixing red, green and blue (Python works with a quite different model of RGB, inverting the order of the colors, so the final model is BGR).\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"images/Resources/RGB.png\" width = 25% /></div>\n",
    "<br>\n",
    "\n",
    "Just like we said at the beginning of the notebook, one of the main objectives is to detect colors in images. For this specific task, we will use a color space know as HSV (Hue Saturation Value) that is a closer model of how humans perceive colors, this a non linear model of RGB with cylindrical coordinates.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"images/Resources/HSV.png\" width = 25% /></div>\n",
    "<br>\n",
    "\n",
    "For the next exercise, we will apply a color filter to the next image. The main idea of this exercise is to pull apart each of the three colors.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"images/Course_images/Filtering.png\" width = 15% /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### *Color Filtering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well if you were working with just Open CV you would have something similar to the next code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "import cv2\n",
    "\n",
    "#Import the numpy library which will help with some matrix operations\n",
    "import numpy as np \n",
    "\n",
    "image = cv2.imread('Filtering.png')\n",
    "\n",
    "#I resized the image so it can be easier to work with\n",
    "image = cv2.resize(image,(300,300))\n",
    "\n",
    "#Once we read the image we need to change the color space to HSV\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#Hsv limits are defined\n",
    "#here is where you define the range of the color you´re looking for\n",
    "#each value of the vector corresponds to the H,S & V values respectively\n",
    "min_green = np.array([50,220,220])\n",
    "max_green = np.array([60,255,255])\n",
    "\n",
    "min_red = np.array([170,220,220])\n",
    "max_red = np.array([180,255,255])\n",
    "\n",
    "min_blue = np.array([110,220,220])\n",
    "max_blue = np.array([120,255,255])\n",
    "\n",
    "\n",
    "#This is the actual color detection \n",
    "#Here we will create a mask that contains only the colors defined in your limits\n",
    "#This mask has only one dimention, so its black and white }\n",
    "mask_g = cv2.inRange(hsv, min_green, max_green)\n",
    "mask_r = cv2.inRange(hsv, min_red, max_red)\n",
    "mask_b = cv2.inRange(hsv, min_blue, max_blue)\n",
    "\n",
    "#We use the mask with the original image to get the colored post-processed image\n",
    "res_b = cv2.bitwise_and(image, image, mask= mask_b)\n",
    "res_g = cv2.bitwise_and(image,image, mask= mask_g)\n",
    "res_r = cv2.bitwise_and(image,image, mask= mask_r)\n",
    "\n",
    "cv2.imshow('Green',res_g)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Resources/green.png\" width = 20% /></div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "cv2.imshow('Red',res_r)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Resources/red.png\" width = 20% /></div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "cv2.imshow('Blue',res_b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Resources/blue.png\" width = 20% /></div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to prove this with the architecture we use in ROS. Try this exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **live_class** package you created before, create a new file named **color_filter.py**, and paste the below code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**color_filter.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ColorFilter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.image_sub = rospy.Subscriber(\"/camera/rgb/image_raw\",Image,self.camera_callback)\n",
    "        self.bridge_object = CvBridge()\n",
    "\n",
    "    def camera_callback(self,data):\n",
    "        try:\n",
    "            # We select bgr8 because its the OpenCV encoding by default\n",
    "            cv_image = self.bridge_object.imgmsg_to_cv2(data, desired_encoding=\"bgr8\")\n",
    "        except CvBridgeError as e:\n",
    "            print(e)\n",
    "        example_path = '/home/user/notebook_ws/images/Course_images/Filtering.png'\n",
    "            \n",
    "        image = cv2.imread(example_path)\n",
    "        #I resized the image so it can be easier to work with\n",
    "        image = cv2.resize(image,(300,300))\n",
    "\n",
    "        #Once we read the image we need to change the color space to HSV\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        #Hsv limits are defined\n",
    "        #here is where you define the range of the color you are looking for\n",
    "        #each value of the vector corresponds to the H,S & V values respectively\n",
    "        min_green = np.array([50,220,220])\n",
    "        max_green = np.array([60,255,255])\n",
    "\n",
    "        min_red = np.array([170,220,220])\n",
    "        max_red = np.array([180,255,255])\n",
    "\n",
    "        min_blue = np.array([110,220,220])\n",
    "        max_blue = np.array([120,255,255])\n",
    "\n",
    "\n",
    "        #This is the actual color detection \n",
    "        #Here we will create a mask that contains only the colors defined in your limits\n",
    "        #This mask has only one dimention, so its black and white }\n",
    "        mask_g = cv2.inRange(hsv, min_green, max_green)\n",
    "        mask_r = cv2.inRange(hsv, min_red, max_red)\n",
    "        mask_b = cv2.inRange(hsv, min_blue, max_blue)\n",
    "\n",
    "        #We use the mask with the original image to get the colored post-processed image\n",
    "        res_b = cv2.bitwise_and(image, image, mask= mask_b)\n",
    "        res_g = cv2.bitwise_and(image,image, mask= mask_g)\n",
    "        res_r = cv2.bitwise_and(image,image, mask= mask_r)\n",
    "\n",
    "        cv2.imshow('Original',image)\n",
    "        cv2.imshow('Green',res_g)\n",
    "        cv2.imshow('Red',res_r)\n",
    "        cv2.imshow('Blue',res_b)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    color_filter_object = ColorFilter()\n",
    "    rospy.init_node('color_filter_node', anonymous=True)\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a launch file named **color_filter.launch**, that starts the above program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**color_filter.launch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<launch>\n",
    "    <node pkg=\"live_class\" type=\"color_filter.py\" name=\"color_filter\"  output=\"screen\">\n",
    "    </node>\n",
    "</launch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will visualize something similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Course_images/color.png\"  /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see it? You have already tested some filters of HSV, **GREAT JOB!** However, you are not using the robot yet... so why don't we use **cv_bridge** and everything? Let's go for it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make 3 diferents filters, and show these 3 filters and the original image from the drone. We want to see in one image only the grass, in another one only the water, and in the other one only the roof of the house. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **live_class** package you created before, create a new file named **color_filter2.py**, and paste the below code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**color_filter2.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ColorFilter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.image_sub = rospy.Subscriber(\"/camera/rgb/image_raw\",Image,self.camera_callback)\n",
    "        self.bridge_object = CvBridge()\n",
    "\n",
    "    def camera_callback(self,data):\n",
    "        try:\n",
    "            # We select bgr8 because its the OpenCV encoding by default\n",
    "            cv_image = self.bridge_object.imgmsg_to_cv2(data, desired_encoding=\"bgr8\")\n",
    "        except CvBridgeError as e:\n",
    "            print(e)\n",
    "        example_path = '/home/user/notebook_ws/images/Course_images/Filtering.png'\n",
    "            \n",
    "        #image = cv2.imread(example_path)\n",
    "        #I resized the image so it can be easier to work with\n",
    "        image = cv2.resize(cv_image,(300,300))\n",
    "\n",
    "        #Once we read the image we need to change the color space to HSV\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        #Hsv limits are defined\n",
    "        #here is where you define the range of the color you are looking for\n",
    "        #each value of the vector corresponds to the H,S & V values respectively\n",
    "        min_green = np.array([40,50,50])\n",
    "        max_green = np.array([60,255,255])\n",
    "\n",
    "        min_red = np.array([0,45,142])\n",
    "        max_red = np.array([10,255,155])\n",
    "\n",
    "        min_blue = np.array([100,50,50])\n",
    "        max_blue = np.array([120,255,255])\n",
    "\n",
    "\n",
    "        #This is the actual color detection \n",
    "        #Here we will create a mask that contains only the colors defined in your limits\n",
    "        #This mask has only one dimention, so its black and white }\n",
    "        mask_g = cv2.inRange(hsv, min_green, max_green)\n",
    "        mask_r = cv2.inRange(hsv, min_red, max_red)\n",
    "        mask_b = cv2.inRange(hsv, min_blue, max_blue)\n",
    "\n",
    "        #We use the mask with the original image to get the colored post-processed image\n",
    "        res_b = cv2.bitwise_and(image, image, mask= mask_b)\n",
    "        res_g = cv2.bitwise_and(image,image, mask= mask_g)\n",
    "        res_r = cv2.bitwise_and(image,image, mask= mask_r)\n",
    "\n",
    "        cv2.imshow('Original',image)\n",
    "        cv2.imshow('Green',res_g)\n",
    "        cv2.imshow('Red',res_r)\n",
    "        cv2.imshow('Blue',res_b)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    color_filter_object = ColorFilter()\n",
    "    rospy.init_node('color_filter_node', anonymous=True)\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutting down\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything goes fine, you would have something similar to this. Have a look at the below gif!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"images/Course_images/color_filter.gif\"  /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOOD JOB!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission  completed!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you liked this video, please support us!\n",
    "# Really... we need your support!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can you support us?\n",
    "## 1. Subscribe to our ROS online academy and become a Master of ROS Development\n",
    "\n",
    "Go to our online academy. There is no faster way and funnier to learn ROS because we use the same\n",
    "method we did here.\n",
    "\n",
    "**We call the 30/70 method**\n",
    "\n",
    "\n",
    "* **30% of the time learning theory**\n",
    "* **70% of the time practicing with simulated robots**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logos/somecourses.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check it out at http://robotignite.academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **OpenCV for Robotics** (COMING SOON) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Buy one ROS Developers T-shirt or one of our mugs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logos/mugs.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logos/T-shirts.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can buy them at our Teespring area (https://teespring.com/stores/ros-developers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Give us a like in Youtube and subscribe to the channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Go to our Youtube Channel (https://www.youtube.com/channel/UCt6Lag-vv25fTX3e11mVY1Q) and subscribe (it is free!!!)**\n",
    "* **Give us a like to this video**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEEP PUSHING YOUR ROS LEARNING WITH PATIENCE AND GOOD HUMOUR!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the future, Become a ROS DEVELOPER"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "latex_metadata": {
   "chapter": "2 - Topics",
   "chapter_title": "Unit 2. Topics Part 2",
   "course_title": "ROS BASICS IN 5 DAYS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
